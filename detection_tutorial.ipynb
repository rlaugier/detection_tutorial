{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3c676-078a-48dc-8506-971af67f3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm, ncx2, chi2\n",
    "#plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89a433-2709-4062-8898-5e27330c38ec",
   "metadata": {},
   "source": [
    "# Tutorial and toy comparison between different statistical tests of detection\n",
    "\n",
    "Measurement instruments, (astronomical instruments included) produce obsevable quantities (i.e. numbers) designed to inform us on the object of our inquiry. However, measurements are random variables, meaning that their values vary randomly around the actual measure according to a statistical law. In other words, the measurement process produce some \"noise\" around the \"signal\" that we want to study. While some conclusions at high S/N (signal to noise ratio) can be made at first glance when looking at the data, most cutting-edge results can only be made at low S/N. In this regime, it can be difficult to make (statistically) informed decisions based on the wiggling numbers, especially since it we are not very familiar with the values we expect in the presence of significant signal.\n",
    "\n",
    "This notebook will guide you through some of the basic mathematical tools necessary to do a practical implementation of the different tests showcased in **Ceau et al. 2019**$^1$. It will guide you from basic concepts of statistics all the way to powerful, field-ready statistical tests. The formalism described here is not the only one that is mathematically sound, and many bridges can be found to other approaches.\n",
    "\n",
    "$^1$ https://ui.adsabs.harvard.edu/abs/2019A%26A...630A.120C/abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531122a-d1d6-4232-bc09-6f7febfee510",
   "metadata": {},
   "source": [
    "## Prerequisites on errors\n",
    "\n",
    "Here we are mostly interested in the detection of features around point sources, in other words, we wish to be able to chose between **two mutually exclusive scenarios** (called hypotheses).\n",
    "The principle of basic statistical tests is to assess the risk of being wrong when rejecting one hypothesis, called the null hypothesis. \n",
    "\n",
    "In our case, the **null hypothesis, $\\mathcal{H}_0$**, always represents the default case where there is no signal of interest, that is of a perfectly point-like source (more precisely a perfectly centro-symmetric souce in the case of **closure phase**, **kernel phase** or **kernel null** data, including the **differential null** obtained with double-Bracewell nullers).\n",
    "\n",
    "The **alternative hypothesis $\\mathcal{H}_1$** represent the case where a signal of interest is present in the meausurement.\n",
    "\n",
    "To be able to calculate the risk of rejecting $\\mathcal{H}_0$, we need to model the measurement process (the model must be valid in both hypothesese).\n",
    "In our case, we will use the following:\n",
    "\n",
    "We consider that the measurments described by the vector $\\mathbf{y}$ gathering a series of $n$ values and are affected by a random error described by the vector $\\boldsymbol{\\varepsilon}$ and a signal of interest represented by the model vector $\\mathbf{x}$.\n",
    "\n",
    "As mentionned above, under $\\mathcal{H}_0$, $\\mathbf{x}$ is a null vector and we can write:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\mathcal{H}_0 : \\mathbf{y} = \\boldsymbol{\\varepsilon} \\\\\n",
    "    \\mathcal{H}_1 : \\mathbf{y} = \\mathbf{x} + \\boldsymbol{\\varepsilon}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02d494-3e51-440c-b9dd-d148e24c90c1",
   "metadata": {},
   "source": [
    "This kind of model always assume that the error vector $\\boldsymbol{\\varepsilon}$ follows :\n",
    "1. a normal distribution \n",
    "1. of stadard deviation 1\n",
    "1. centered around 0\n",
    "1. with uncorrelated elements\n",
    "\n",
    "In summary $ \\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(0,\\mathbf{I})$\n",
    "\n",
    "In this context, 1. is generelly true, and 3. is true in theory. However in most cases 2. and 4. are generally false with interferometric data$^2$. However, simple algebraic procedures can be used to translate the raw data $\\mathbf{y}'$ into usable observables $\\mathbf{y}$ that fit these prerequesites. **Those will be described in a different tutorial**, but a preview is showed in appendix A.\n",
    "\n",
    "Note that in practice, the true limitation of this testing approach are determined by our ability to:\n",
    "* calibrate (and therefore measure) the biases and therefore enforce 3,\n",
    "* evaluate the amplitude of errors and evaluate and therefore enforce 2.\n",
    "\n",
    "\n",
    "$^2$ : In the case of Closure/Kernel phases, the pixel-level (photon and read) noises become correlated. Even in the case of kernel-nulls where the observable quantity comes from the simple difference of two pixels, the instrumental errors are correlated between the different wavelength channels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f9463-be10-459b-a136-a673d9bf6bd3",
   "metadata": {},
   "source": [
    "## First create some model ($\\mathbf{x}$) and data ($\\mathbf{y}$).\n",
    "\n",
    "$\\mathbf{x}$ is a vector corresponding to the signal we want to detect. It is the expectation of $\\mathbf{y}$ under $\\mathcal{H}_1$.\n",
    "\n",
    "Here we use a simple sine wave. Adjust the amplitude `A` to create different SNR. (We will leave the standard deviation of noise to 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a40ff-1945-45e7-b1f5-68c79d6bc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 0.85 # default = 0.85\n",
    "ndim = 50 # default = 50\n",
    "phi = 0.2 # default = 0.2\n",
    "t = np.arange(ndim, dtype=np.float64)\n",
    "x = A*np.sin(0.5*t + phi) # x is the model signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd7814-ca37-4f96-bda8-1558aa435b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the measurement noise epsilon around the signal x\n",
    "noise_bank = np.random.multivariate_normal(mean=np.zeros(ndim),cov=np.eye(ndim), size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19bee0-602c-4306-a528-db0b55f5193f",
   "metadata": {},
   "source": [
    "\n",
    "$\\mathbf{y}$ is a vector of observable quantities obtained in an experiment. For the sake of this demonstration, we will draw two versions:\n",
    "* `y_0` obtained under $\\mathcal{H}_0$ (so just noise),\n",
    "* and `y_1` obtained under $\\mathcal{H}_1$, (so the noise offset by a value corresponding to the model `x`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373d767-58d6-4f5d-9ed7-0e64e1349add",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = noise_bank[0,:]\n",
    "y_1 = x + noise_bank[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f53e6-fb29-4774-bb00-beee053030ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the data we've generated!\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(y_0, label=f\"$y$ (obsered under $\\mathcal{{H}}_0$, just noise)\", color=\"C0\")\n",
    "plt.plot(y_1, label=f\"$y$ (observed under $\\mathcal{{H}}_1$, noisy signal)\", color=\"C1\")\n",
    "plt.plot(x, label=f\"$x$ (model signal)\", color=\"C1\", linestyle=\"--\")\n",
    "plt.legend(fontsize=\"xx-small\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b69f94-9284-4c50-8cf6-facbf08acdc1",
   "metadata": {},
   "source": [
    "### Fig. 1:  A plot of the model signal, the noise, and the noisy signal. With the default parameters, the signal under $\\mathcal{H}_1$ is \"buried\" in the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703f080-9bfc-4ab1-a164-fbc9616d1e34",
   "metadata": {},
   "source": [
    "As we can see in Figs. 1 and 2, we are in a case of low S/N, in which it is difficult to give an interpretation by eye. This is a case where statistics must be used to inform on a result, both for the instrument scientist trying to predict the performance of the instrument, and for the observer, trying to decide what conclusion to draw.\n",
    "\n",
    "This is called statistical inference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d4a09-778b-4bbb-b0c3-585c1094e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.linspace(np.min(x), np.max(x), 100)\n",
    "fig = plt.figure(dpi=150, figsize=(6,3))\n",
    "plt.subplot(121)\n",
    "plt.errorbar(x, y_0, yerr=1., fmt=\"none\", label=f\"$\\mathbf{{y}} | \\mathcal{{H}}_0$\", \n",
    "            alpha=0.5)\n",
    "plt.plot(xvals, xvals, color=\"gray\", linestyle=\"--\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(f\"Observation $y$\")\n",
    "plt.xlabel(f\"Model $x$\")\n",
    "plt.subplot(122)\n",
    "plt.errorbar(x, y_1, yerr=1., fmt=\"none\", label=f\"$\\mathbf{{y}} | \\mathcal{{H}}_1$\",\n",
    "            alpha=0.5)\n",
    "plt.plot(xvals, xvals, color=\"gray\", linestyle=\"--\")\n",
    "#plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(f\"Model $x$\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a6002d-be04-4866-8c80-0b9d6f83653b",
   "metadata": {},
   "source": [
    "### Fig. 2:  A correlation plot under $\\mathcal{H}_0$ and $\\mathcal{H}_1$. This type of plots help to identify the resemblance between the model and the data, by plotting each on a different axis, with a dashed line representing $\\mathbf{y} = \\mathbf{x}$ . In cases with high S/N, we sould be able to see the correlation trend between the two. In cases that are actually a challenge for the detection test, it should be barely noticeable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a698977b-80e5-4ab6-8d73-72919035bc10",
   "metadata": {},
   "source": [
    "# Statistical tests\n",
    "\n",
    "Statistical test or hypothesis tests are built around the statistics of the errors in the data. They provide a decision tool that is built around the false alarm rate $P_{FA}$  which is the probability to reject $\\mathcal{H}_0$ when it is actually true.\n",
    "\n",
    "The approach we follow here will be driven by the choice of a value for $P_{FA}$. \n",
    "\n",
    "### You can adjust your False Alarm rate $P_{FA}$ here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418baf2-1cc3-42cb-b31a-2636b6ac9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfa = 0.05 # default: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a240a4-2805-4ae3-bc30-fb562dbccd62",
   "metadata": {},
   "source": [
    "A test is composed of two main ingredients:\n",
    "* A test statistic $T: \\mathbf{y} \\rightarrow T(\\mathbf{y})$ that can be computed based on observed data.\n",
    "* A threshold $\\xi$ that will be used to select an hypothesis or make a decision.\n",
    "\n",
    "The way that $\\xi$ can be computed to obtain certain properties (most notably a certain $P_{FA}$) is one of most important aspects of a detection test.\n",
    "\n",
    "Depending on how $T(\\mathbf{y})$ compares with $\\xi$, we will accept either one or the other of the hypotheses.\n",
    "\n",
    "$$T(\\mathbf{y}) \\underset{\\mathcal{H}_0}{\\overset{\\mathcal{H}_1}{\\gtrless}} \\xi $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c368bb-84a0-411b-85ad-e987651e7235",
   "metadata": {},
   "source": [
    "In the approach taken by Ceau et al. 2019, $T$ is constructed based on a likelihood ratio\n",
    "$$ \\frac{\\mathscr{l}(\\mathcal{H}_1; \\mathbf{y})}{\\mathscr{l}(\\mathcal{H}_0; \\mathbf{y})}  \\underset{\\mathcal{H}_0}{\\overset{\\mathcal{H}_1}{\\gtrless}} \\xi' $$\n",
    "This likelihood can be expressed (**Scharf & Friedlander 1994**):\n",
    "$$ \\mathscr{l}(\\mathcal{H}_1; y) =  (2\\pi)^{-\\frac{n}{2}} \\mathrm{exp}\\Big( -\\frac{1}{2}(\\mathbf{x} - \\mathbf{y})^T(\\mathbf{x} - \\mathbf{y}) \\Big)$$\n",
    "where $n$ is the length of the data vectors. By simplifying and taking the logarithm, this ratio can be simplified and turned into a difference.\n",
    "\n",
    "The main difference between the different tests being how well refined the model is under $\\mathcal{H}_1$, leading to different expressions of $\\mathscr{l}(\\mathcal{H}_1; y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5ddf7-075b-47bb-a668-3d392f28ea34",
   "metadata": {},
   "source": [
    "# Energy detector test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8650e-a6ac-4048-ba6a-12edf642508d",
   "metadata": {},
   "source": [
    "Under this test, nothing is known on the type of signal under $\\mathcal{H}_1$. Under such circumstances, the best estimate for the model is $\\hat{\\mathbf{x}} = \\mathbf{y} $, leading to equation (21) in **Ceau et al. 2019**, and therefore:\n",
    "$$ T_E(\\mathbf{y}) := \\mathbf{y}^T\\mathbf{y} \\underset{\\mathcal{H}_0}{\\overset{\\mathcal{H}_1}{\\gtrless}} \\xi $$\n",
    "\n",
    "This is extremely simple. It is also referred to as the $\\chi^2$ test. It is adequate when nothing is known about the signature $\\mathbf{x}$.\n",
    "\n",
    "But as you may have guessed, a test is worthless without a rational way to set its threshold $\\xi$. This can be expressed with based on the distribution of $T_E$ under the different hypotheses:\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\mathcal{H}_0 : T_E(\\mathbf{y}) \\sim \\chi^2_p (\\mathrm{loc}=0) \\\\\n",
    "    \\mathcal{H}_1 : T_E(\\mathbf{y}) \\sim \\chi^2_p (\\mathrm{loc}=\\mathbf{x}^T\\mathbf{x})\n",
    "\\end{cases}\n",
    "$$\n",
    "Note how therefore be expressed based on the inverse of the Cumulative Distribution Function ($\\mathrm{CDF}^{-1}$) of the $\\chi^2$ distribution. This inverse is somtimes called Percent Point Function ($\\mathrm{PPF}$ and we will find it under this name in `scipy.stats.ncx2`, here imported as `ncx2`.$^2$ Pay close attention to the way those parameters are provided to the function, as this api is relatively tricky. The following cell queries the first lines of the documentation string of this class:\n",
    "\n",
    "$^2$: Note that we could also have used `scipy.stats.chi2` for the cases under $\\mathcal{H}_0$, but here we prefer the uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484021a-77a3-4775-b50c-ec98f9728ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ncx2.__doc__[:1100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9193e-d210-46d2-a9f0-f6642ff98f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsi = ncx2.ppf(1-Pfa, df=ndim, nc=0.)\n",
    "print(f\"Pfa (chosen) = {Pfa}\")\n",
    "print(f\"xsi = {xsi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07a0e9-a58c-4715-ab8a-623458b58877",
   "metadata": {},
   "source": [
    "Now determining $P_{Det}$ requires assumptions on the signal to determine how its amplitude is translated into values of $T_E$. Here, we use the model signal $\\mathbf{x}$ that we prepared before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c91100-66cb-4549-bfc3-f90889658b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTx = x.T.dot(x)\n",
    "Pdet_Pfa = 1 - ncx2.cdf(xsi, ndim, xTx)\n",
    "print(f\"Pfa (chosen) = {Pfa}\")\n",
    "print(f\"Pdet = {Pdet_Pfa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2969f-5631-4367-9fab-3f509873c379",
   "metadata": {},
   "source": [
    "This is best represented as PDF plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995b6e9-d5c1-4cdf-8840-e701d6f55acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.linspace(0., 2*xsi, 1000)\n",
    "zdet = z[z>xsi]\n",
    "zndet = z[z<xsi]\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(z, ncx2.pdf(z, df=ndim, nc=0), label=f\"PDF($T_{{E}} | \\mathcal{{H}}_0$)\")\n",
    "plt.fill_between(zdet,  ncx2.pdf(zdet, df=ndim, nc=0), alpha=0.3, label=f\"$P_{{FA}}$\")# , hatch=\"//\"\n",
    "plt.plot(z, ncx2.pdf(z, df=ndim, nc=xTx), label=f\"PDF($T_{{E}}| \\mathcal{{H}}_1$)\")\n",
    "plt.fill_between(zdet,  ncx2.pdf(zdet, df=ndim, nc=xTx), alpha=0.3, label=f\"$P_{{Det}}$\")\n",
    "plt.axvline(xsi, color=\"gray\", linestyle=\"--\", label=f\"$\\\\xi(P_{{FA}}={Pfa})$\")\n",
    "plt.xlabel(f\"$T_{{E}}$\")\n",
    "plt.ylabel(f\"$PDF(T_{{E}})$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538b491-dc89-41f4-9adf-bbe2b874a3c3",
   "metadata": {},
   "source": [
    "### Fig. 3 : The PDF (probability density function) of $T_E(\\mathbf{y})$ under both hypotheses. We cans see $\\xi$ as the user's attemps to discriminate between the two hypotheses in a clean cut. The integrals represented by filled regions correspond to the values of $P_{FA}$ and $P_{det}$. With the default parameters, this not very sensitive and rejects most of the cases under $\\mathcal{H}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763fa47-bbd5-42d2-96e8-b60be5d89ac4",
   "metadata": {},
   "source": [
    "The test therefore tells us if we have statistical reasons to reject the Null hypothesis ($\\mathcal{G}_0$, that is that the target has no detectable features). Gaining knowledge on what features must be done by other means (model fitting, statistical inference, image reconstruction...).\n",
    "\n",
    "Note that this energy detector test is not very powerful. It is however still usefull, as $P_{Det}$ and the sensitivity can be evaluated mathematically, and so it can help determine the a lower bound for the performance of an instrument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0bf5c-7cfd-4b61-8cd2-a71a19c3c012",
   "metadata": {},
   "source": [
    "# Neyman-Pearson test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b7db5-27a2-4d5a-a26c-d82540f3c858",
   "metadata": {},
   "source": [
    "Such a likelihood ratio test will be most sensitive when we perfectly know the expected signature. In this case, the test statistic can be written:\n",
    "$$ T_{NP}(\\mathbf{y}, \\mathbf{x}) = \\mathbf{y}^T\\mathbf{x} \\underset{\\mathcal{H}_0}{\\overset{\\mathcal{H}_1}{\\gtrless}} \\xi $$\n",
    "(see equations (13) and (14) of **Ceau et al. 2019**.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\mathcal{H}_0 : T_{NP}(\\mathbf{y}, \\mathbf{x}) \\sim \\mathcal{N} (\\mathrm{loc}=0, \\mathrm{scale}=\\sqrt{\\mathbf{x}^T\\mathbf{x}}) \\\\\n",
    "    \\mathcal{H}_1 : T_{NP}(\\mathbf{y}, \\mathbf{x}) \\sim \\mathcal{N} (\\mathrm{loc}=\\mathbf{x}^T\\mathbf{x}, \\mathrm{scale}=\\sqrt{\\mathbf{x}^T\\mathbf{x}}) \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note how in this case, the test statistics (and its distribution) also depend on a model signal $\\mathbf{x}$.\n",
    "\n",
    "This time, we will need a model for the normal distribution that we find in `scipy.stats.norm` here imported as `norm`. We lookup the api for it with the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83530af1-8a91-4758-9d4e-d3753cf78ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm.__doc__[:1100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90c2bc-abab-40cf-af2d-4e6aefca8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTx = x.T.dot(x)\n",
    "xsi = np.sqrt(xTx)*norm.ppf(1-Pfa)\n",
    "print(f\"xsi = {xsi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f92048-9a8b-4b86-9179-575daec6fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pdet_Pfa = 1 - norm.cdf((xsi - xTx)/np.sqrt(xTx), loc=0, scale=1)\n",
    "print(f\"Pfa (chosen) = {Pfa}\")\n",
    "print(f\"Pdet = {Pdet_Pfa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c063aa-6688-494c-9699-0e97ee3c9021",
   "metadata": {},
   "source": [
    "We can see that (with the default parameters) the detection is still very high. This shows that this test is more sensitive than the energy detector ($T_E$) test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9409b5-c2c8-4703-8621-fde3c1a5577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.linspace(-0.5*xTx, 4*xsi, 1000)\n",
    "zdet = z[z>xsi]\n",
    "zndet = z[z<xsi]\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(z, norm.pdf(z, loc=0, scale=np.sqrt(xTx)), label=f\"Pdf($T_{{NP}} | \\mathcal{{H}}_0$)\")\n",
    "plt.fill_between(zdet,  norm.pdf(zdet, loc=0, scale=np.sqrt(xTx)), alpha=0.3, label=f\"$P_{{FA}}$\")# , hatch=\"//\"\n",
    "#plt.fill_between(z[], )\n",
    "plt.plot(z, norm.pdf(z, loc=xTx, scale=np.sqrt(xTx)), label=f\"Pdf($T_{{NP}}| \\mathcal{{H}}_1$)\")\n",
    "plt.fill_between(zdet,  norm.pdf(zdet, loc=xTx, scale=np.sqrt(xTx)), alpha=0.3, label=f\"$P_{{Det}}$\")\n",
    "plt.axvline(xsi, color=\"gray\", linestyle=\"--\",  label=f\"$\\\\xi(P_{{FA}}={Pfa})$\")\n",
    "plt.xlabel(f\"$T_{{NP}}$\")\n",
    "plt.ylabel(f\"$PDF(T_{{NP}})$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25435330-ae3c-42aa-a636-1d50154e3241",
   "metadata": {},
   "source": [
    "### Fig. 4 : The PDF for $T_{NP}(\\mathbf{y})$, to be compared with Fig.3. Here, the result is more sensitive than with $T_E$ and under the default parameters, it catches most of the cases under $\\mathcal{H}_1$ (i.e. $P_{det}$ is high)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455de84-a789-4883-97af-5e201cbc2dca",
   "metadata": {},
   "source": [
    "Note that this Neyman-Pearson test is the most powerfull test possible. However, it is also much less useful in practice. Indeed, it requires that the signature sought be known in advance. Therefore in can only be used to confirm a detection, but the result will bring no additional knowledge on the feature detected.\n",
    "\n",
    "However, it allows us to compute relatively easily the theoretical upper bound of the performance in detection of a given instrument or approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73c34e-e5e2-4627-9372-b04db0da4d79",
   "metadata": {},
   "source": [
    "# Receiver operator characteristic\n",
    "\n",
    "The performance of the tests can be compared as a function of chosen false alarm probability $P_{FA}$. This is called the Receiver Operator Characteristic (ROC) plot for a given model signal $\\mathbf{x}$.\n",
    "\n",
    "The diagonal of the plot ($P_{Det}=P_{FA}$) represents a purely random test, with a coin toss located at $(0.5, 0.5)$. Note that we are usually interested in the performance at very low false alarm rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c775906-b40e-4673-9a94-42f3ee155d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pfas = np.linspace(0., 0.1, 1000)\n",
    "Pfas = np.logspace(-10,-0.2, 100)\n",
    "Pdet_NP_Pfa = 1 - norm.cdf((np.sqrt(xTx)*norm.ppf(1-Pfas) - xTx)/np.sqrt(xTx))\n",
    "Pdet_E_Pfa = 1 - ncx2.cdf(ncx2.ppf(1-Pfas, ndim, 0.), ndim, xTx)\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(Pfas, Pdet_NP_Pfa, label=f\"ROC($T_{{NP}}$)\")\n",
    "plt.plot(Pfas, Pdet_E_Pfa, label=f\"ROC($T_{{E}}$)\")\n",
    "plt.plot(Pfas, Pfas, color=\"gray\", linestyle=\"--\", label=\"Random\")\n",
    "plt.axvline(Pfa, color=\"gray\", label=f\"$P_{{FA}}={Pfa:.3f}$\")\n",
    "#plt.gca().set_aspect(\"equal\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.xlabel(f\"$P_{{FA}}(\\\\xi)$\")\n",
    "plt.ylabel(f\"$P_{{Det}}(\\\\xi)$\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, None)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798dfd2-e99e-457b-b2fb-169bbb004f14",
   "metadata": {},
   "source": [
    "### Fig. 5: The compared ROC for $T_{NP}$ and $T_E$ for the model signature $\\mathbf{x}$. We can see the $T_{NP}$ is extremely sensitive even at low $P_{FA}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b74f74-5118-475e-b5cd-6b6d6e65f3a1",
   "metadata": {},
   "source": [
    "# Matched subspace detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c9c0a8-f886-4214-86e5-214fb0df5c57",
   "metadata": {},
   "source": [
    "Tests can be found in between those two limit performances that are adapted to the detection of specific families of signatures, rather than one exact signature. This constitutes a *Generalized* Likelihood Ratio test (GLRt). For this we build a family of signals $\\{\\mathbf{x}\\}=\\{f(\\mathbf{a})\\}$ that are spawned from a model of a small number of parameters here represented by the vector $\\mathbf{a}$ such that it represents a subspace of the possible models. For the example of a companion fainter star these parameters could be $\\rho$ the separation, $\\theta$ the position angle, and $c$ the contrast (or luminosity for the case of nulling). It could also include several companions or other types of detectable features.\n",
    "\n",
    "The model vector of interest becomes the model signal that maximizes the likelihood of the data, called the Maximum Likelihood Estimate (MLE):\n",
    "$$ \\hat{\\mathbf{x}} :=  \\underset{\\mathbf{a}}{\\mathrm{argmax}}\\Big( \\mathscr{l}(\\mathbf{a};\\mathbf{y}) \\Big).$$\n",
    "This MLE can not always be computed analytically. In the general case, one will rely on a gradient descent and a good starting point estimate (or tricks like simulated annealing) to identify it reliably.\n",
    "\n",
    "As derived in **Ceau et al. 2019** in equations (30) and (31), the resulting test can be written:\n",
    "$$ T_{B}(\\mathbf{y}) = 2 \\mathbf{y}^T\\hat{\\mathbf{x}} - \\hat{\\mathbf{x}}^T\\hat{\\mathbf{x}} \\underset{\\mathcal{H}_0}{\\overset{\\mathcal{H}_1}{\\gtrless}} \\xi $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ccac9-ad87-47c7-8657-c9bff84f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_B(y, xhat):\n",
    "    Tb = 2*y.T.dot(xhat) - xhat.T.dot(xhat)\n",
    "    return Tb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db794f-7935-40ea-820b-f25021de2952",
   "metadata": {},
   "source": [
    "As a consequence, the distribution of $T_B(y)$ is not known analytically, even under $\\mathcal{H}_0$, and therefore the determination of $P_{FA}$ requires tedious processes, like the Monte Carlo simulations used in the paper. Furthermore, computing $P_{Det}$ to evaluate the performance requires more MC simulations under $\\mathcal{H}_1$, and for eacho of the model parameters considered (like a 3D grid for a single companion detection).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744986f-4c1e-438e-b56e-32c0299fbee6",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "So we will need a reliable way to obtain a MLE. The library `lmfit` is a good choice, as it provides access to a wide array of powerful tools with a nice API. Direct use of the methods like `scipy.optimize.leastsq` is also a popular choice, and is functionnally very similar to what will be shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcaed20-6a4f-43b0-863f-f05b8664a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import minimize, Parameters\n",
    "parameters = Parameters()\n",
    "parameters.add(\"A\",value=1.,  min=0, max=4.)\n",
    "parameters.add(\"omega\", value=0.5, min=0., max=1.)\n",
    "parameters.add(\"phi\", value=0.2, min=-np.pi, max=np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f7cec-c33a-4c4d-b06d-492e431b8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def residual_sine(myparameters, target):\n",
    "    myA = myparameters[\"A\"]\n",
    "    myomega = myparameters[\"omega\"]\n",
    "    myphi = myparameters[\"phi\"]\n",
    "    asignal = myA*np.sin(myomega*t + myphi)\n",
    "    return asignal - target\n",
    "def residual_sine_quick(myparameters, target):\n",
    "    asignal = myparameters[\"A\"]*np.sin(myparameters[\"omega\"]*t + myparameters[\"phi\"])\n",
    "    return asignal - target\n",
    "def get_MLE(parameters, y, verbose=False, method=\"leastsq\", **fit_kws):\n",
    "    sol = minimize(residual_sine, parameters, args=(y,), method=method, **fit_kws)\n",
    "    xhat = residual_sine(sol.params, np.zeros_like(y))\n",
    "    if verbose:\n",
    "        display(sol)\n",
    "    return xhat\n",
    "\n",
    "\n",
    "def get_MLE_robust(parameters, y, verbose=False, method=None, **fit_kws):\n",
    "    sol0 = minimize(residual_sine_quick, parameters, args=(y,), method=\"brute\", **fit_kws)\n",
    "    sol = minimize(residual_sine_quick, sol0.params, args=(y,), method=\"leastsq\", **fit_kws)\n",
    "    xhat = residual_sine(sol.params, np.zeros_like(y))\n",
    "    if verbose:\n",
    "        display(sol)\n",
    "    return xhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c608237-2f7b-40bf-85d9-39d6aa6ccdd9",
   "metadata": {},
   "source": [
    "We build a large set of observations to do this MC simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297de0b6-969d-4c71-85c7-9141ffcbe5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0s = noise_bank[:500,:]\n",
    "y_1s = x + noise_bank[-500:,:] # We will call the noise bank from the bottom for the signals under H_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e7f21-a83c-4f23-8d46-ad8cda49bc84",
   "metadata": {},
   "source": [
    "Here is an example of the fitting for the parameters under each of the hypothesis. For the characterization under $\\mathcal{H}_0$, it is important to find the global maximum of the likelihood, so we use two steps.\n",
    "\n",
    "1. A brute-force approach identifies the most promising valley.\n",
    "2. A gradient descent algorithm finds the corresponding local minimum (or maximum in this case).\n",
    "\n",
    "Note that in practice one can often leverage the linearity with regard to the contrast parameter to explore lower-dimension **correlation maps** or **colinearity maps** in order to find an acceptable starting point for the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ca867-2e25-475b-8dbb-c4b571fb5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat1 = get_MLE_robust(parameters, y_1s[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405bbda-4bf7-4c07-9888-0e3455af5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat0 = get_MLE_robust(parameters, y_0s[0], verbose=True, method=\"brute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df38b3-6b54-45ef-b6f8-c7745fa99f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(t, y_0, label=f\"$\\mathbf{{y}}$ (obsered under $\\mathcal{{H}}_0$ just noise)\",\n",
    "        color=\"C0\")\n",
    "plt.plot(t, xhat0, label=f\"$\\hat{{\\mathbf{{x}}}}$ (fitted under $\\mathcal{{H}}_0$, just noise)\",\n",
    "        color=\"C0\", linestyle=\"--\")\n",
    "plt.plot(t, y_1, label=f\"$\\mathbf{{y}}$ (observed under $\\mathcal{{H}}_1$, noisy signal)\",\n",
    "        color=\"C1\")\n",
    "plt.plot(t, xhat1, label=f\"$\\hat{{\\mathbf{{x}}}}$ (fitted under $\\mathcal{{H}}_1$, noisy signal)\",\n",
    "        color=\"C1\", linestyle=\"--\")\n",
    "plt.plot(t, x, label=f\"$\\mathbf{{x}}$ (model signal)\",\n",
    "        color=\"gray\", linestyle=\"--\")\n",
    "plt.legend(fontsize=\"xx-small\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd45c4-ad43-4239-a085-7b0df0d3eacf",
   "metadata": {},
   "source": [
    "### Fig. 6: Plot comparing signals and their MLE models (best fit) under the different hypotheses. While in the case of $\\mathcal{H}_0$, the fitted signal fits only noise, the fitted signal under $\\mathcal{H}_1$ is a good approximation of the model signal (indicating that it has found the correct local optimum). This has the effect of moving the problem to a subspace of fewer dimensions (the model parameters, rather than the number of observables). However, the whole reasonning relies on the validity of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e1339-fd95-43dc-aa19-246df7fed6f5",
   "metadata": {},
   "source": [
    "In order to obtain a good evaluation of the performance, a large number of realizations must be used, leading to possibly long execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c36a43-6220-41b1-8891-e953bde0a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "xhat_0s = []\n",
    "for i in tqdm(range(y_0s.shape[0])):\n",
    "    myxhat = get_MLE_robust(parameters, y_0s[i,:])\n",
    "    xhat_0s.append(myxhat)\n",
    "xhat_0s = np.array(xhat_0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55adc86-c728-4393-bf2c-0fac29642ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xhat_1s = []\n",
    "for i in tqdm(range(y_1s.shape[0])):\n",
    "    myxhat = get_MLE_robust(parameters, y_1s[i,:])\n",
    "    xhat_1s.append(myxhat)\n",
    "xhat_1s = np.array(xhat_1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878e594-7d28-4bc6-a343-6dbb49397777",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_B0s = np.array([T_B(y_0s[i,:], xhat_0s[i,:]) for i in range(y_0s.shape[0])])\n",
    "T_B1s = np.array([T_B(y_1s[i,:], xhat_1s[i,:]) for i in range(y_1s.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86257079-de38-4c2a-9375-2ce2665cb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.hist(T_B0s, histtype=\"step\", bins=50, label=f\"($T_{{B}}(\\mathbf{{y}}) | \\mathcal{{H}}_0$)\")\n",
    "plt.hist(T_B1s, histtype=\"step\", bins=50, label=f\"($T_{{B}}(\\mathbf{{y}}) | \\mathcal{{H}}_1$)\")\n",
    "plt.legend()\n",
    "plt.xlabel(f\"$T_{{B}}$\")\n",
    "plt.ylabel(f\"$\\mathrm{{hist}}(T_{{B}})$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b2ecf-cfff-40b5-a8b7-16d2cce3dfe7",
   "metadata": {},
   "source": [
    "### Fig. 7: Histograms of the ditribution of $T_B$ under both hypotheses. This may be seen as an empirical counterpart to Figures 3. and 4., as there are no theoretical distributions for this test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec60fd2-3823-4dd6-ab5b-1c019dcb3624",
   "metadata": {},
   "source": [
    "Based on these, we can compute the ROC for $T_E$ by comparing the number of larger and smaller results under bot $\\mathcal{H}_0$ and $\\mathcal{H}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c8a38-9013-4f95-952b-d6b79ffbd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax = np.max(T_B1s)\n",
    "Tmin = np.min(T_B0s)\n",
    "NTs = T_B0s.shape[0]\n",
    "xsis_B = np.linspace(Tmin, Tmax, 100)\n",
    "Pfas_B = []\n",
    "Pdets_B = []\n",
    "for i, axsi in enumerate(xsis_B):\n",
    "    Pfas_B.append(1/NTs * np.count_nonzero(T_B0s>axsi))\n",
    "    Pdets_B.append(1/NTs * np.count_nonzero(T_B1s>axsi))\n",
    "Pfas_B = np.array(Pfas_B)\n",
    "Pdets_B = np.array(Pdets_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2663f5b-fade-46e6-9cfb-bc020f311481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pfas = np.linspace(0., 0.1, 1000)\n",
    "#Pfas = np.logspace(-10,-0.2, 100)\n",
    "#Pdet_NP_Pfa = 1 - norm.cdf((np.sqrt(xTx)*norm.ppf(1-Pfas) - xTx)/np.sqrt(xTx))\n",
    "#Pdet_E_Pfa = 1 - ncx2.cdf(ncx2.ppf(1-Pfas, ndim, 0.), ndim, xTx)\n",
    "fig = plt.figure(dpi=150)\n",
    "plt.plot(Pfas, Pdet_NP_Pfa, label=f\"ROC($T_{{NP}}$)\")\n",
    "plt.plot(Pfas, Pdet_E_Pfa, label=f\"ROC($T_{{E}}$)\")\n",
    "plt.plot(Pfas_B, Pdets_B, label=f\"ROC($T_{{B}}$)\")\n",
    "plt.plot(Pfas, Pfas, color=\"gray\", linestyle=\"--\", label=\"Random\")\n",
    "plt.axvline(Pfa, color=\"gray\", label=f\"$P_{{FA}}={Pfa:.3f}$\")\n",
    "#plt.gca().set_aspect(\"equal\")\n",
    "#plt.xscale(\"log\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.xlabel(f\"$P_{{FA}}(\\\\xi)$\")\n",
    "plt.ylabel(f\"$P_{{Det}}(\\\\xi)$\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, np.max(Pfas))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c8a8c-be0c-4fa7-a005-5d57b75b2885",
   "metadata": {},
   "source": [
    "### Fig. 8: ROC plot comparing the three different tests. The plot for $T_B$ bears some uncertainty as it was built with a limited number of realizations (1000 by default). However it shows significant improvement over the agnostic $T_E$ test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65fb73-7da1-48a3-889b-23004bf9d32d",
   "metadata": {},
   "source": [
    "## $T_B$ in practice\n",
    "\n",
    "As we can see in this compared ROC plot, $T_B$ is much more sensitive than $T_E$ at the cost of asumptions on the observed signal, but it also provides a MLE of the model parameters as a by-product.\n",
    "\n",
    "On the other hand, picking a value for a threshold on the basis of a target $P_{FA}$ is non-trivial, and may require some heavy computation cost. In practice a acceptable approach is to ask the question: \"If this is a detection ($\\xi_{\\mathbf{y}} = T_{B}(\\mathbf{y})$), then what would be the false alarm rate $\\hat{P_{FA}} = P_{FA, \\xi_{\\mathbf{y}}}$?\". The problem is that an accurate determination of this can still take some time. The approach proposed in my PhD thesis (Laugier 2020) is to use an iterative approach to compute with some flexibility an upper bound for this probability.\n",
    "\n",
    "In this approach, one draws successively MC realizations of $\\mathbf{y}$ under $\\mathcal{H}_0$ to compare them to $T_{B}(\\mathbf{y})$, and each time increments either $n_+$ or $n_-$, dependting if the result was larger or smaller than $T_{B}(\\mathbf{y})$. Two conditions can be used to stop:\n",
    "\n",
    "* The total number of loops exceeds a value $N$ (e.g. $N=100$)\n",
    "    * In allowing an evaluation of $\\hat{P_{FA}}$ down to about $1/N$\n",
    "* The counter $n_+$ exceeds a value $n$ (e.g. $n=N/10$)\n",
    "    * Therefore allowing to stop the computation if the False alarm rate is estimated larger than e.g. 10%\n",
    "    \n",
    "In most cases under $\\mathcal{H}_0$, the loop will stop at around $2n$ realizations, and at N realizations under  $\\mathcal{H}_1$. Such a process can even be resumed (for a promising result) at no additional cost if one wants to improve the upper bound set on $P_{FA}$ after stopping at $N$.\n",
    "\n",
    "Of course, these are only rough estimates, an must be used with care."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b350a8-c722-4f95-beca-d0ea8a7e61a4",
   "metadata": {},
   "source": [
    "### Let us see an example\n",
    "\n",
    "First initialize the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7fc658-77df-481c-b489-b002bacf79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # Default 100\n",
    "n = 10 # Default 10\n",
    "\n",
    "\n",
    "y_ex = y_1s[0] # Here we just pick one realization for the sake of the example from either y_1s or y_0s.\n",
    "xhat_ex = get_MLE_robust(parameters, y_ex)\n",
    "T_B_ex = T_B(y_ex, xhat_ex)\n",
    "nplus = 0\n",
    "nminus = 0\n",
    "nstop = False\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57ee7d-a421-4d50-a14d-613739bf661a",
   "metadata": {},
   "source": [
    "Then the loop can be ran again and again to improve the accuracy of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27401ced-62c4-4aa9-adbe-b9b097fff000",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    i += 1\n",
    "    y0_ex = np.random.multivariate_normal(mean=np.zeros(ndim),cov=np.eye(ndim), size=1).flatten()\n",
    "    xhat0_ex = get_MLE_robust(parameters, y0_ex)\n",
    "    T_B0_ex = T_B(y0_ex, xhat0_ex)\n",
    "    if T_B0_ex>=T_B_ex:\n",
    "        nplus += 1\n",
    "    else :\n",
    "        nminus += 1\n",
    "    print(f\"Loop {i}/{N} : n+={nplus}, n-={nminus}\", end=\"\\r\")\n",
    "    if nplus>n:\n",
    "        est_pfa = nplus/i\n",
    "        print(\"\\n\")\n",
    "        print(f\"P_FA >= {est_pfa:.4f}\")\n",
    "        break\n",
    "    if i>=N:\n",
    "        if nplus == 0:\n",
    "            est_pfa = 1/i\n",
    "            print(\"\\n\")\n",
    "            print(f\"P_FA <= {est_pfa:.4f}\")\n",
    "        else:\n",
    "            est_pfa = nplus/i\n",
    "            print(\"\\n\")\n",
    "            print(f\"P_FA ~ {est_pfa:.4f}\")\n",
    "            \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76384e2b-995f-46a4-8ff2-abdf41118430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more precision, we can just increase N, then relauch the loop.\n",
    "N=300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfe2a3-c370-4a91-b79f-eff579ce81fa",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "$T_{NP}$ and $T_{E}$ can be used to place bounds on the performance of a given approach as they represent two extremes in the usage of *a priori* knowledge on the target. Both these cases offer mathematical approaches to evaluate performance based on a constrain on $P_{FA}$.\n",
    "\n",
    "$T_B$ is formalization of a GLR test that can be adapted around any parametric model. This flexibility comes at the cost of simplicity, as it becomes difficult to evaluate the performance, and $P_{FA}$. Although an evaluation of the performance on a large set of parameters is computationaly costly, it can still be used on the field thanks to some algorithmic tricks.\n",
    "\n",
    "Always keep in mind that the performance (and usability) of the tests depend on two main factors:\n",
    "\n",
    "* Our capability to produce unbiased measurements, and therefore in practice the quality of our calibration process\n",
    "* Our capability to produce a reliable estimation of the errors\n",
    "\n",
    "Those two criteria are not independant. Whatever biases are likely to remain in the data should be taken into account in the error estimates.\n",
    "\n",
    "The main offenders are therefore errors evolving on intermediate timescales: two fast to be correctly calibrated and too slow to be easily measured in an empirical covariance.\n",
    "\n",
    "What adds up to that is the problem that a cutting-edge survey with unprecedented sensitivity can expect to make discoveries even around calibrators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee29366-21c0-410e-aa84-addf42947ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5d74d-a8da-4ada-86cf-832310163c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fca62e-baf9-49ca-91b1-f2c3a292dd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5a3a2-f27f-4e81-a22c-2464de8dd80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5f0a3-ee4e-4e41-ae2f-8a4923534c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c413bb3-544d-417d-83c9-fe1abc4ca4dd",
   "metadata": {},
   "source": [
    "### Appendix A on signal whitening\n",
    "Steps to fulfill the previously mentionned hypothesis will be illustrated in a different tutorial, but here is a short overview:\n",
    "* The measurement is unbiased (calibration has been applied).\n",
    "* The measurement vector has been scaled to a standard deviation of 1.\n",
    "* The measurement vector $\\mathbf{y}$ is expressed in a basis where the error components $\\boldsymbol{\\varepsilon}$ are uncorrelated.\n",
    "\n",
    "In the case of observable vectors that are normally distributed and centered around 0 under $\\mathcal{H}_0$, this can be obtained from the correlated and arbitrarily scaled values through the use of a simple whitening transformation.\n",
    "$$ \\mathbf{y}_p = \\mathbf{x}_p + \\boldsymbol{\\varepsilon}_p$$\n",
    "$$ \\boldsymbol{\\varepsilon}_p \\sim \\mathcal{N}(0, \\boldsymbol{\\Sigma}_p) $$\n",
    "One could also say:\n",
    "$$ \\mathrm{Cov}(\\boldsymbol{\\varepsilon_p}) = \\boldsymbol{\\Sigma_p}$$\n",
    "Then we can obtained the whitened signal $\\mathbf{y}$ by taking:\n",
    "$$ \\mathbf{y} = \\mathbf{W}.\\mathbf{y}_p$$\n",
    "where $\\mathbf{W}$ is the inverse matrix square root of this covariance matrix:\n",
    "$$ \\mathbf{W} = \\boldsymbol{\\Sigma_p}^{-\\frac{1}{2}} .$$\n",
    "One then obtains $\\mathrm{Cov}(\\boldsymbol{\\varepsilon}) = \\boldsymbol{\\Sigma} = \\mathbf{I}$, and allows us tu use $\\mathbf{y}$ with the aformentionned assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ba6c5-fe5c-479c-af66-9be0dfff4b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
